from langchain.prompts import ChatPromptTemplate
from langchain.document_loaders import UnstructuredFileLoader
from langchain.embeddings import OllamaEmbeddings
from langchain.schema.runnable import RunnableLambda, RunnablePassthrough
from langchain.storage import LocalFileStore
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores.faiss import FAISS
from langchain.chat_models import ChatOllama
from langchain.callbacks.base import BaseCallbackHandler
import streamlit as st

st.set_page_config(
    page_title="Summarizer",
    page_icon="ğŸ”’",
)


class ChatCallbackHandler(BaseCallbackHandler):
    message = ""

    def on_llm_start(self, *args, **kwargs):
        self.message_box = st.empty()

    def on_llm_end(self, *args, **kwargs):
        save_message(self.message, "ai")

    def on_llm_new_token(self, token, *args, **kwargs):
        self.message += token
        self.message_box.markdown(self.message)


llm = ChatOllama(
    model="bllossom-8B:latest",
    temperature=0.1,
    streaming=True,
    callbacks=[
        ChatCallbackHandler(),
    ],
)


def save_message(message, role):
    if "messages" not in st.session_state:
        st.session_state["messages"] = []
    st.session_state["messages"].append({"message": message, "role": role})


def send_message(message, role, save=True):
    with st.chat_message(role):
        st.markdown(message)
    if save:
        save_message(message, role)


def paint_history():
    if "messages" not in st.session_state:
        st.session_state["messages"] = []
    for message in st.session_state["messages"]:
        send_message(
            message["message"],
            message["role"],
            save=False,
        )


prompt = ChatPromptTemplate.from_template(
    """ë‹¤ìŒì€ í™˜ìì™€ ì˜ì‚¬ ê°„ì˜ ì§„ë£Œ ëŒ€í™” ë‚´ìš©ì´ì•¼. ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì•„ë˜ ì˜ˆì‹œì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ìš”ì•½í•´ì¤˜. 
    Contextì˜ ì •ë³´ ì™¸ì— ìƒˆë¡œìš´ ì •ë³´ë¥¼ ì¶”ê°€í•˜ì§€ ë§ˆ. Examples í˜•ì‹ì— ë§ê²Œ ì˜ ì‘ì„±í•´ì£¼ë©´ $50 ì¤„ê²Œ

    Context: {context}

    ----------------------------------------------------------------
    Examples:
        ë³‘ëª…: ì²œì‹
        ì§„ë£Œ ë‚´ìš©: í¡ì…ê¸° ì‚¬ìš© í›„ í˜¸í¡ ê°œì„ . ë‚ ì”¨ ë‚˜ì  ë•Œ ë§ˆìŠ¤í¬ ì°©ìš©, ì‹¤ë‚´ ìš´ë™ ë° ë¨¼ì§€ ê´€ë¦¬ í•„ìš”. í•œ ë‹¬ í›„ í˜¸í¡ê¸° ê²€ì‚¬ ì˜ˆì •.

        ë³‘ëª…: ì†Œí™”ë¶ˆëŸ‰
        ì§„ë£Œ ë‚´ìš©: ì•½ë¬¼ ë³µìš© í›„ ì¦ìƒ í˜¸ì „. ê·œì¹™ì ì¸ ì‹ì‚¬ì™€ ì†Œí™” ì˜ ë˜ëŠ” ìŒì‹ ì„­ì·¨, ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬ ë° ì‹ì‚¬ í›„ ì‚°ì±… ê¶Œì¥. í•œ ë‹¬ í›„ ì¬ì§„ ì˜ˆì •.

        ë³‘ëª…: ì•ˆêµ¬ ê±´ì¡°ì¦
        ì§„ë£Œ ë‚´ìš©: ì¸ê³µëˆˆë¬¼ ì‚¬ìš© í›„ ê°œì„ . 20-20-20 ê·œì¹™ ê¶Œì¥, í•˜ë£¨ 4-5ë²ˆ ì¸ê³µëˆˆë¬¼ ì‚¬ìš© ê°€ëŠ¥. ì‹¤ë‚´ ìŠµë„ ìœ ì§€ í•„ìš”. í•œ ë‹¬ í›„ ì¬ì§„ ì˜ˆì •.

        ë³‘ëª…: ì•Œë ˆë¥´ê¸° í”¼ë¶€ì—¼
        ì§„ë£Œ ë‚´ìš©: ì—°ê³  ì‚¬ìš© í›„ ê°œì„ . ì•Œë ˆë¥´ê¸° ìœ ë°œ ìš”ì¸ í”¼í•˜ê¸°, ë³´ìŠµì œ ì‚¬ìš© ë° ëœ¨ê±°ìš´ ë¬¼ ìƒ¤ì›Œ í”¼í•˜ê¸° í•„ìš”. í•œ ë‹¬ í›„ ì¬ì§„ ì˜ˆì •.
    ----------------------------------------------------------------

    """
)


st.title("Summarizer")

st.markdown(
    """
ìš”ì•½ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.
        
"""
)

send_message("ìš”ì•½í•  ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”", "ai", save=False)
paint_history()
message = st.chat_input("ìš”ì•½í•  ë‚´ìš©ì„ ë„£ì–´ì£¼ì„¸ìš”")
if message:
    send_message(message, "human")
    chain = (
        {
            "context": RunnablePassthrough(),
        }
        | prompt
        | llm
    )
    with st.chat_message("ai"):
        chain.invoke(message)
